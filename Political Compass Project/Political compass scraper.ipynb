{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from twikit import Client\n",
    "from twikit import TwitterException \n",
    "from twikit import TooManyRequests\n",
    "from twikit.utils import Endpoint\n",
    "from translate import Translator\n",
    "from math import ceil\n",
    "import time\n",
    "import json\n",
    "import requests\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'flow_token': 'g;171383153823331646:-1713831538284:iYbMdL1yeuuz2V9IlNzbk3zZ:14',\n",
       " 'status': 'success',\n",
       " 'subtasks': [{'subtask_id': 'LoginSuccessSubtask',\n",
       "   'open_account': {'user': {'id': 1547081484695216130,\n",
       "     'id_str': '1547081484695216130',\n",
       "     'name': 'Eloragh Espie',\n",
       "     'screen_name': 'EloraghEspie'},\n",
       "    'next_link': {'link_type': 'subtask',\n",
       "     'link_id': 'next_link',\n",
       "     'subtask_id': 'SuccessExit'},\n",
       "    'attribution_event': 'login'}},\n",
       "  {'subtask_id': 'SuccessExit',\n",
       "   'open_link': {'link': {'link_type': 'subtask',\n",
       "     'link_id': 'next_link',\n",
       "     'subtask_id': 'LoginOpenHomeTimeline'}}},\n",
       "  {'subtask_id': 'LoginOpenHomeTimeline',\n",
       "   'open_home_timeline': {'next_link': {'link_type': 'abort',\n",
       "     'link_id': 'next_link'}}}]}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this API requires authentication\n",
    "f = open('authentication.txt', 'r')\n",
    "auth = f.read()\n",
    "f.close()\n",
    "auth_token = auth.split(\"\\n\")\n",
    "\n",
    "# don't hardcode your email and password into something!!!\n",
    "# the auth is in gitignore so I won't get hacked\n",
    "USERNAME = str(auth_token[0])\n",
    "EMAIL = str(auth_token[1])\n",
    "PASSWORD = str(auth_token[2])\n",
    "\n",
    "# Initialize client\n",
    "client = Client(language='en-US', http2=True)\n",
    "\n",
    "# Login to the service with provided user credentials\n",
    "client.login(\n",
    "    auth_info_1=USERNAME ,\n",
    "    auth_info_2=EMAIL,\n",
    "    password=PASSWORD\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Twitter LOVES to ban people when they log in repeatedly\n",
    "# saving the cookies makes sure I don't get banned (often)\n",
    "\n",
    "client.get_cookies()\n",
    "client.save_cookies('IGNOREcookies.json')\n",
    "with open('IGNOREcookies.json', 'r', encoding='UTF8') as f:\n",
    "    client.set_cookies(json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# housekeeping function\n",
    "# each different method uses a different API endpoint\n",
    "# each different API endpoint has a rate limit\n",
    "# you can hit it a certain number of times per a time period (usually 15 minutes)\n",
    "# this tells me how much time I have left if I've hit the rate limit\n",
    "\n",
    "def get_limit_reset_time(endpoint: str):\n",
    "    res = requests.get(\n",
    "        endpoint,\n",
    "        headers=client._base_headers,\n",
    "        cookies=client.get_cookies()\n",
    "    )\n",
    "    return ceil(int(res.headers['x-rate-limit-reset']) - time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Tweet id=\"1351951465674276869\">, <Tweet id=\"1351918910199631872\">, <Tweet id=\"1351906918667677696\">, <Tweet id=\"1351897267666608129\">, <Tweet id=\"1351731172989050882\">, <Tweet id=\"1351711040933830659\">, <Tweet id=\"1351653131248041984\">, <Tweet id=\"1351630258114502656\">, <Tweet id=\"1351599720012021761\">, <Tweet id=\"1351367275094310912\">, <Tweet id=\"1351333542547001344\">, <Tweet id=\"1351265605840633858\">, <Tweet id=\"1351228360123318272\">, <Tweet id=\"1350981483062706177\">, <Tweet id=\"1350926118409289730\">, <Tweet id=\"1350878051710750725\">, <Tweet id=\"1350634446475694080\">, <Tweet id=\"1350593782832500737\">, <Tweet id=\"1350562220367884289\">, <Tweet id=\"1350515133034819584\">]\n"
     ]
    }
   ],
   "source": [
    "# timeout check for scraping tweet IDs\n",
    "try:\n",
    "    print(client.search_tweet(\n",
    "        f'from:JoeBiden since:2020-01-01 until:2021-03-01', 'Latest', count=40\n",
    "    ))\n",
    "except TooManyRequests:\n",
    "    reset_time = get_limit_reset_time(Endpoint.USER_TWEETS)\n",
    "    print(f'rate limit is reset after {reset_time} seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Tweet id=\"1351951465674276869\">\n"
     ]
    }
   ],
   "source": [
    "# timeout check for processing tweets\n",
    "try:\n",
    "    print(client.get_tweet_by_id(1351951465674276869))\n",
    "except TooManyRequests:\n",
    "    reset_time = get_limit_reset_time(Endpoint.USER_TWEETS)\n",
    "    print(f'rate limit is reset after {reset_time} seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# another housekeeping function\n",
    "# if I'm suddenly getting 403 errors, I can use this to check if I've been banned\n",
    "# sometimes I just have to go on the browser and reauthenticate\n",
    "\n",
    "def check_user_status(user_id):\n",
    "    \"\"\"\n",
    "    True if the user is active, otherwise false (not exists or suspended).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        client.get_user_by_id(user_id)\n",
    "    except TwitterException as e:\n",
    "        if str(e).startswith('Invalid user id'):\n",
    "            return False\n",
    "        raise e\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "check_user_status(1547081484695216130)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT: the user handle, a beginning and end of a date range\n",
    "# OUTPUT: the user handle, the user_ID, and the scraped tweets\n",
    "def get_all_tweets(handle, since, until):\n",
    "\n",
    "    # load the cookies so you don't login a million times and get banned\n",
    "    client.load_cookies('IGNOREcookies.json')\n",
    "\n",
    "    # initialize the list we will store our data in\n",
    "    mass_tweets = []\n",
    "\n",
    "    since = f'{since}-01-01'\n",
    "    until = f'{until}-12-31'\n",
    "\n",
    "    # this will pull the first forty tweets\n",
    "    tweets = client.search_tweet(\n",
    "        f'from:{handle} since:{since} until:{until}', 'Top'\n",
    "    )\n",
    "    tweets1 = [tweet.id for tweet in tweets]\n",
    "    mass_tweets += tweets1\n",
    "\n",
    "    # if it returns an empty list, the user had no available tweets during the date time range\n",
    "    if len(tweets) == 0:\n",
    "        return([])\n",
    "    \n",
    "    # this will keep looking for tweets until a certain number of them has been reached\n",
    "    while len(tweets) > 0 and len(mass_tweets) < 30:\n",
    "\n",
    "        # this API provides a 'tweet' object, but we only want the id when we return\n",
    "        tweets = tweets.next()\n",
    "        tweets1 = [tweet.id for tweet in tweets]\n",
    "        mass_tweets += tweets1\n",
    "\n",
    "        # keep pulling tweets until number is hit or there are none left\n",
    "\n",
    "        # we need to make a check in case we've hit the max number of tweets we can scrape\n",
    "        # this prevents us from pinging the API for no reason\n",
    "        if len(tweets) == 0:\n",
    "            print(\"No more tweets\")\n",
    "            break\n",
    "        else:\n",
    "            print(f'Total tweets = {len(mass_tweets)}')\n",
    "            continue\n",
    "\n",
    "    return(mass_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tweets(handle, user_id, name, tweet_ids, since):\n",
    "    # load the cookies so you don't login a million times and get banned\n",
    "    client.load_cookies('IGNOREcookies.json')\n",
    "\n",
    "    # initialize a list to store all tuples\n",
    "    tweets = []\n",
    "\n",
    "    i = 0\n",
    "    for tweet_id in tweet_ids:\n",
    "        try:\n",
    "            # using the IDs we pulled from above\n",
    "            tweet = client.get_tweet_by_id(tweet_id)\n",
    "\n",
    "            # we have international data\n",
    "            # this will translate it and identify it's translation\n",
    "            if tweet.lang != 'en':\n",
    "                translator = Translator(to_lang='en')\n",
    "                tweet_text = translator.translate(tweet.text)\n",
    "                tweets.append((int(tweet.id), int(user_id), name, handle, tweet_text, str(tweet.lang), 'True', 'en', tweet.created_at_datetime))\n",
    "\n",
    "            # otherwise we just move on\n",
    "            else:\n",
    "                tweets.append((int(tweet.id), int(user_id), name, handle, str(tweet.text), str(tweet.lang), 'False', 'null', str(tweet.created_at_datetime), since))\n",
    "        \n",
    "            print(f'Tweet {i} processed')\n",
    "            i += 1\n",
    "\n",
    "        # it throws an Index Error if the tweet has been deleted/ is not available\n",
    "        except IndexError:\n",
    "            print(f'Index Error: {tweet}')\n",
    "\n",
    "    return tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(813286, 'Barack Obama', 'BarackObama', 2008)\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "conn = sqlite3.connect('tweets.db')\n",
    "c = conn.cursor()\n",
    "\n",
    "c.execute(\"\"\" SELECT twitter_user_id, politician_name, twitter_handle, election_year\n",
    "            FROM coordinates\n",
    "            WHERE twitter_active_during_election = 'True'\n",
    "            \"\"\")\n",
    "active_user_list = c.fetchall()\n",
    "print(active_user_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_list = active_user_list.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_list = user_list[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(813286, 'Barack Obama', 'BarackObama', 2008)\n"
     ]
    }
   ],
   "source": [
    "print(user_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tweets = 39\n",
      "39 tweets collected for Barack Obama for 2008 election\n",
      "0 tweets collected for Joe Biden for 2008 election\n",
      "Total tweets = 39\n",
      "39 tweets collected for Dennis Kucinich for 2008 election\n",
      "Total tweets = 39\n",
      "39 tweets collected for Mike Huckabee for 2008 election\n",
      "0 tweets collected for Fred Thompson for 2008 election\n",
      "Total tweets = 39\n",
      "39 tweets collected for Chris Dodd for 2008 election\n",
      "Tweet 0 processed\n",
      "Tweet 1 processed\n",
      "Tweet 2 processed\n",
      "Tweet 3 processed\n",
      "Tweet 4 processed\n",
      "Tweet 5 processed\n",
      "Tweet 6 processed\n",
      "Tweet 7 processed\n",
      "Tweet 8 processed\n",
      "Tweet 9 processed\n",
      "Tweet 10 processed\n",
      "Tweet 11 processed\n",
      "Tweet 12 processed\n",
      "Tweet 13 processed\n",
      "Tweet 14 processed\n",
      "Tweet 15 processed\n",
      "Tweet 16 processed\n",
      "Tweet 17 processed\n",
      "Tweet 18 processed\n",
      "Tweet 19 processed\n",
      "Tweet 20 processed\n",
      "Tweet 21 processed\n",
      "Tweet 22 processed\n",
      "Tweet 23 processed\n",
      "Tweet 24 processed\n",
      "Tweet 0 processed\n",
      "Tweet 1 processed\n",
      "Tweet 2 processed\n",
      "Tweet 3 processed\n",
      "Tweet 4 processed\n",
      "Tweet 5 processed\n",
      "Tweet 6 processed\n",
      "Tweet 7 processed\n",
      "Tweet 8 processed\n",
      "Tweet 9 processed\n",
      "Tweet 10 processed\n",
      "Tweet 11 processed\n",
      "Tweet 12 processed\n",
      "Tweet 13 processed\n",
      "Tweet 14 processed\n",
      "Tweet 15 processed\n",
      "Tweet 16 processed\n",
      "Tweet 17 processed\n",
      "Tweet 18 processed\n",
      "Tweet 19 processed\n",
      "Tweet 20 processed\n",
      "Tweet 21 processed\n",
      "Tweet 22 processed\n",
      "Tweet 23 processed\n",
      "Tweet 24 processed\n",
      "Tweet 0 processed\n",
      "Tweet 1 processed\n",
      "Tweet 2 processed\n",
      "Tweet 3 processed\n",
      "Tweet 4 processed\n",
      "Tweet 5 processed\n",
      "Tweet 6 processed\n",
      "Tweet 7 processed\n",
      "Tweet 8 processed\n",
      "Tweet 9 processed\n",
      "Tweet 10 processed\n",
      "Tweet 11 processed\n",
      "Tweet 12 processed\n",
      "Tweet 13 processed\n",
      "Tweet 14 processed\n",
      "Tweet 15 processed\n",
      "Tweet 16 processed\n",
      "Tweet 17 processed\n",
      "Tweet 18 processed\n",
      "Tweet 19 processed\n",
      "Tweet 20 processed\n",
      "Tweet 21 processed\n",
      "Tweet 22 processed\n",
      "Tweet 23 processed\n",
      "Tweet 24 processed\n",
      "Tweet 0 processed\n",
      "Tweet 1 processed\n",
      "Tweet 2 processed\n",
      "Tweet 3 processed\n",
      "Tweet 4 processed\n",
      "Tweet 5 processed\n",
      "Tweet 6 processed\n",
      "Tweet 7 processed\n",
      "Tweet 8 processed\n",
      "Tweet 9 processed\n",
      "Tweet 10 processed\n",
      "Tweet 11 processed\n",
      "Tweet 12 processed\n",
      "Tweet 13 processed\n",
      "Tweet 14 processed\n",
      "Tweet 15 processed\n",
      "Tweet 16 processed\n",
      "Tweet 17 processed\n",
      "Tweet 18 processed\n",
      "Tweet 19 processed\n",
      "Tweet 20 processed\n",
      "Tweet 21 processed\n",
      "Tweet 22 processed\n",
      "Tweet 23 processed\n",
      "Tweet 24 processed\n"
     ]
    }
   ],
   "source": [
    "final_tweet_list = []\n",
    "no_tweets_list = []\n",
    "\n",
    "while len(user_list) > 0:\n",
    "\n",
    "    tweet_id_list = []\n",
    "    i = 0\n",
    "\n",
    "    # this first loop pulls tweet IDs for politicians\n",
    "    while (i < 5 and len(user_list) > 0):\n",
    "        \n",
    "        # we're only ever concerned with the first value\n",
    "        # we pop this later to keep the list moving\n",
    "        lst = user_list[0]\n",
    "\n",
    "        # all of our parameters for the functions\n",
    "        user_id = lst[0]\n",
    "        name = lst[1]\n",
    "        handle = lst[2]\n",
    "        since = lst[3]\n",
    "        until = lst[3]+1\n",
    "\n",
    "        # pull tweet IDs that we will user in second while loop\n",
    "        tweet_ids = get_all_tweets(handle, since=since, until=until)\n",
    "        print(f'{len(tweet_ids)} tweets collected for {name} for {since} election')\n",
    "\n",
    "        # pop user so we're not in an infinite loop\n",
    "        user_list.pop(0)\n",
    "\n",
    "        # we only add to the counter if that person actually had tweets to process\n",
    "        if len(tweet_ids) > 0:\n",
    "            i+=1\n",
    "            tweet_id_list.append([handle, user_id, name, tweet_ids, since])\n",
    "        \n",
    "        # I want to keep track of which politicians didn't tweet during their election year\n",
    "        else:\n",
    "            no_tweets_list.append([user_id, name, handle, since])\n",
    "        \n",
    "    tweet_id_list_copy = tweet_id_list.copy()\n",
    "    tweet_list = []\n",
    "\n",
    "    # this second loop processes and cleans the tweets\n",
    "    # it formats each tweet into a list that can be executed into the SQL database\n",
    "    while len(tweet_id_list_copy) > 0:\n",
    "        \n",
    "        # same thing here, we're only ever concerned with index 0\n",
    "        # these are lists of lists\n",
    "        index = tweet_id_list_copy[0]\n",
    "\n",
    "        # all the parameters we need\n",
    "        handle = index[0]\n",
    "        user_id = index[1]\n",
    "        name = index[2]\n",
    "        year = index[4]\n",
    "        \n",
    "        # we only want to do up to 25 tweets per politician\n",
    "        # this means we can process 5 politicians per rate timeout\n",
    "        # 150 tweets per 15 minutes\n",
    "        # not great but it's free\n",
    "\n",
    "        if len(index[3]) > 25:\n",
    "\n",
    "            # random sample in an attempt to stay unbiased\n",
    "            tweet_ids = random.sample(index[3], 25)\n",
    "        else:\n",
    "            tweet_ids = index[3]\n",
    "        \n",
    "        # process the tweets and add them to our holding list from above\n",
    "        tweets = process_tweets(handle, user_id, name, tweet_ids, year)\n",
    "        tweet_list.append(tweets)\n",
    "        \n",
    "        # pop the first index to keep the loop going\n",
    "        tweet_id_list_copy.pop(0)\n",
    "    \n",
    "    # once we've run both loops, we add to the final list\n",
    "    # this way we don't lose the data once it restarts\n",
    "    final_tweet_list += tweet_list\n",
    "\n",
    "    # rate limit protection\n",
    "    # we can only process 150 tweets per 15 minutes\n",
    "    # getting errors from rate limits throws off the whole thing\n",
    "    # this prevents that from happening\n",
    "    # time.sleep(900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'int'>\n",
      "<class 'int'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'int'>\n"
     ]
    }
   ],
   "source": [
    "for item in final_tweet_list[0][0]:\n",
    "    print(type(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "table tweets already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m conn \u001b[38;5;241m=\u001b[39m sqlite3\u001b[38;5;241m.\u001b[39mconnect(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtweets.db\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m c \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mcursor()\n\u001b[1;32m----> 5\u001b[0m \u001b[43mc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\u001b[38;5;124;43mCREATE TABLE tweets (\u001b[39;49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;124;43m          tweet_id INTEGER,\u001b[39;49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124;43m          user_id INTEGER,\u001b[39;49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124;43m          user_name STRING,\u001b[39;49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;124;43m          user_handle STRING,\u001b[39;49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;124;43m          tweet_text STRING,\u001b[39;49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;124;43m          tweet_original_lang STRING,\u001b[39;49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;124;43m          tweet_translated STRING,\u001b[39;49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;124;43m          tweet_translated_lang STRING,\u001b[39;49m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;124;43m          created_date STRING,\u001b[39;49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;43m          election_year INT\u001b[39;49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;124;43m          )\u001b[39;49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mOperationalError\u001b[0m: table tweets already exists"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "conn = sqlite3.connect('tweets.db')\n",
    "c = conn.cursor()\n",
    "\n",
    "c.execute(\"\"\"CREATE TABLE tweets (\n",
    "          tweet_id INTEGER,\n",
    "          user_id INTEGER,\n",
    "          user_name STRING,\n",
    "          user_handle STRING,\n",
    "          tweet_text STRING,\n",
    "          tweet_original_lang STRING,\n",
    "          tweet_translated STRING,\n",
    "          tweet_translated_lang STRING,\n",
    "          created_date STRING,\n",
    "          election_year INT\n",
    "          )\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "database is locked",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\u001b[38;5;124;43mCREATE TABLE politician_tweets (\u001b[39;49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;43m          tweet_id INTEGER,\u001b[39;49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;43m          user_id INTEGER,\u001b[39;49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;43m          user_name STRING,\u001b[39;49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124;43m          user_handle STRING,\u001b[39;49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;124;43m          tweet_text STRING,\u001b[39;49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124;43m          tweet_original_lang STRING,\u001b[39;49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124;43m          tweet_translated STRING,\u001b[39;49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;124;43m          tweet_translated_lang STRING,\u001b[39;49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;124;43m          created_date STRING,\u001b[39;49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;124;43m          election_year INT\u001b[39;49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;124;43m          )\u001b[39;49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mOperationalError\u001b[0m: database is locked"
     ]
    }
   ],
   "source": [
    "c.execute(\"\"\"CREATE TABLE politician_tweets (\n",
    "          tweet_id INTEGER,\n",
    "          user_id INTEGER,\n",
    "          user_name STRING,\n",
    "          user_handle STRING,\n",
    "          tweet_text STRING,\n",
    "          tweet_original_lang STRING,\n",
    "          tweet_translated STRING,\n",
    "          tweet_translated_lang STRING,\n",
    "          created_date STRING,\n",
    "          election_year INT\n",
    "          )\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x1917257dbc0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn.execute('DROP TABLE tweets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6439688687, 813286, 'Barack Obama', 'BarackObama', 'Watch the town hall meeting last Friday in Allentown, Pa., about the job situation: http://bit.ly/7nQ0WZ', 'en', 'False', 'null', '2009-12-07 19:35:47+00:00', 2008)\n"
     ]
    },
    {
     "ename": "ProgrammingError",
     "evalue": "parameters are of unsupported type",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mProgrammingError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tweet \u001b[38;5;129;01min\u001b[39;00m lst:\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(tweet)\n\u001b[1;32m----> 8\u001b[0m     \u001b[43mc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecutemany\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mINSERT INTO tweets VALUES (?,?,?,?,?,?,?,?,?,?)\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtweet\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m     conn\u001b[38;5;241m.\u001b[39mcommit()\n",
      "\u001b[1;31mProgrammingError\u001b[0m: parameters are of unsupported type"
     ]
    }
   ],
   "source": [
    "# upload data in SQLite table\n",
    "# storing this data is important since this is an unofficial API\n",
    "# every time I access it, I am risking not being able to access it again\n",
    "\n",
    "for lst in final_tweet_list:\n",
    "    for tweet in lst:\n",
    "        print(tweet)\n",
    "        c.executemany(\"INSERT INTO tweets VALUES (?,?,?,?,?,?,?,?,?,?)\", tweet)\n",
    "        conn.commit()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
