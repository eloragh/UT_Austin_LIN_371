{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from twikit import Client\n",
    "from twikit import TwitterException \n",
    "from twikit import TooManyRequests\n",
    "from twikit.utils import Endpoint\n",
    "from translate import Translator\n",
    "from math import ceil\n",
    "import time\n",
    "import json\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this API requires authentication\n",
    "f = open('authentication.txt', 'r')\n",
    "auth = f.read()\n",
    "f.close()\n",
    "auth_token = auth.split(\"\\n\")\n",
    "\n",
    "# don't hardcode your email and password into something!!!\n",
    "# the auth is in gitignore so I won't get hacked\n",
    "USERNAME = str(auth_token[0])\n",
    "EMAIL = str(auth_token[1])\n",
    "PASSWORD = str(auth_token[2])\n",
    "\n",
    "# Initialize client\n",
    "client = Client(language='en-US', http2=True)\n",
    "\n",
    "# Login to the service with provided user credentials\n",
    "client.login(\n",
    "    auth_info_1=USERNAME ,\n",
    "    auth_info_2=EMAIL,\n",
    "    password=PASSWORD\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Twitter LOVES to ban people when they log in repeatedly\n",
    "# saving the cookies makes sure I don't get banned (often)\n",
    "\n",
    "client.get_cookies()\n",
    "client.save_cookies('IGNOREcookies.json')\n",
    "with open('IGNOREcookies.json', 'r', encoding='UTF8') as f:\n",
    "    client.set_cookies(json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# housekeeping function\n",
    "# each different method uses a different API endpoint\n",
    "# each different API endpoint has a rate limit\n",
    "# you can hit it a certain number of times per a time period (usually 15 minutes)\n",
    "# this tells me how much time I have left if I'v hit the rate limit\n",
    "\n",
    "def get_limit_reset_time(endpoint: str):\n",
    "    res = requests.get(\n",
    "        endpoint,\n",
    "        headers=client._base_headers,\n",
    "        cookies=client.get_cookies()\n",
    "    )\n",
    "    return ceil(int(res.headers['x-rate-limit-reset']) - time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# timeout check for scraping tweet IDs\n",
    "try:\n",
    "    print(client.search_tweet(\n",
    "        f'from:JoeBiden since:2020-01-01 until:2021-03-01', 'Latest', count=40\n",
    "    ))\n",
    "except TooManyRequests:\n",
    "    reset_time = get_limit_reset_time(Endpoint.USER_TWEETS)\n",
    "    print(f'rate limit is reset after {reset_time} seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# timeout check for processing tweets\n",
    "try:\n",
    "    print(client.get_tweet_by_id(1351951465674276869))\n",
    "except TooManyRequests:\n",
    "    reset_time = get_limit_reset_time(Endpoint.USER_TWEETS)\n",
    "    print(f'rate limit is reset after {reset_time} seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# another housekeeping function\n",
    "# if I'm suddenly getting 403 errors, I can use this to check if I've been banned\n",
    "# sometimes I just have to go on the browser and reauthenticate\n",
    "\n",
    "def check_user_status(user_id):\n",
    "    \"\"\"\n",
    "    True if the user is active, otherwise false (not exists or suspended).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        client.get_user_by_id(user_id)\n",
    "    except TwitterException as e:\n",
    "        if str(e).startswith('Invalid user id'):\n",
    "            return False\n",
    "        raise e\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "check_user_status(1547081484695216130)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT: the user handle, a beginning and end of a date range\n",
    "# OUTPUT: the user handle, the user_ID, and the scraped tweets\n",
    "def get_all_tweets(handle, since, until):\n",
    "\n",
    "    # load the cookies so you don't login a million times and get banned\n",
    "    client.load_cookies('IGNOREcookies.json')\n",
    "\n",
    "    # initialize the list we will store our data in\n",
    "    mass_tweets = []\n",
    "\n",
    "    since = f'{since}-01-01'\n",
    "    until = f'{until}-06-31'\n",
    "\n",
    "    # this will pull the first forty tweets\n",
    "    tweets = client.search_tweet(\n",
    "        f'from:{handle} since:{since} until:{until}', 'Top'\n",
    "    )\n",
    "\n",
    "    # if it returns an empty list, the user had no available tweets during the date time range\n",
    "    if len(tweets) == 0:\n",
    "        print('No tweets available')\n",
    "        return([])\n",
    "    \n",
    "    # this will keep looking for tweets until a certain number of them has been reached\n",
    "    else:\n",
    "        while len(mass_tweets) >= 0 and len(mass_tweets) < 100:\n",
    "\n",
    "            # this API provides a 'tweet' object, but we only want the id when we return\n",
    "            tweets1 = [tweet.id for tweet in tweets]\n",
    "            mass_tweets += tweets1\n",
    "            time.sleep(1)  # cooldown so we don't get banned\n",
    "\n",
    "            # keep pulling tweets until number is hit or there are none left\n",
    "            tweets = tweets.next()\n",
    "\n",
    "            # we need to make a check in case we've hit the max number of tweets we can scrape\n",
    "            # this prevents us from pinging the API for no reason\n",
    "            if len(tweets) == 0:\n",
    "                print(\"No more tweets\")\n",
    "                break\n",
    "            else:\n",
    "                print(len(mass_tweets))\n",
    "                continue\n",
    "\n",
    "    return(mass_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tweets(handle, user_id, name, tweet_ids):\n",
    "    # load the cookies so you don't login a million times and get banned\n",
    "    client.load_cookies('IGNOREcookies.json')\n",
    "\n",
    "    # initialize a list to store all tuples\n",
    "    tweets = []\n",
    "\n",
    "    for tweet_id in tweet_ids:\n",
    "        try:\n",
    "            # using the IDs we pulled from above\n",
    "            tweet = client.get_tweet_by_id(tweet_id)\n",
    "\n",
    "            # we have international data\n",
    "            # this will translate it and identify it's translation\n",
    "            if tweet.lang != 'en':\n",
    "                translator = Translator(to_lang='en')\n",
    "                tweet = translator.translate(tweet.text)\n",
    "                tweets.append((int(tweet.id), int(user_id), name, handle, tweet, str(tweet.lang), 'True', 'en', tweet.created_at_datetime))\n",
    "\n",
    "            # otherwise we just move on\n",
    "            else:\n",
    "                tweets.append((int(tweet.id), int(tweet_id), name, handle, str(tweet.text), str(tweet.lang), 'False', 'null', tweet.created_at_datetime))\n",
    "\n",
    "        # it throws an Index Error if the tweet has been deleted/ is not available\n",
    "        except IndexError:\n",
    "            print(f'Index Error: {tweet}')\n",
    "\n",
    "    return tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_tweets(active_user_list):\n",
    "    final_list = []\n",
    "    no_tweets = []\n",
    "\n",
    "    while len(active_user_list) > 0:\n",
    "        \n",
    "        lst = active_user_list[0]\n",
    "        user_id = lst[0]\n",
    "        name = lst[1]\n",
    "        handle = lst[2]\n",
    "        since = lst[3]\n",
    "        until = lst[3]+1\n",
    "\n",
    "        try:\n",
    "            tweet_ids = get_all_tweets(handle, since=since, until=until)\n",
    "            print(f'{len(tweet_ids)} tweets collected for {name} for {since} election')\n",
    "\n",
    "            # if they had no tweets for that election year\n",
    "            # add to a separate list to keep track and pop\n",
    "            if len(tweet_ids) == 0:\n",
    "                print(f'{name} for election {since} had no tweets')\n",
    "                no_tweets.append((user_id, name, handle, since))\n",
    "                active_user_list.pop(0)\n",
    "            \n",
    "            # if they had tweets, process them and add to the data list\n",
    "            # we also pop here to keep the while loop moving\n",
    "            else:\n",
    "                tweets2 = process_tweets(handle, user_id, name, tweet_ids)\n",
    "                final_list += tweets2\n",
    "                active_user_list.pop(0)\n",
    "\n",
    "        # cool down when we hit too many requests\n",
    "        # this works well with the while loop\n",
    "        # otherwise we would have to stop and start or batch the entire thing\n",
    "        except TooManyRequests:\n",
    "            reset_time = get_limit_reset_time(Endpoint.USER_TWEETS)\n",
    "            print(f\"Too many requests. Rate limit reset after {reset_time}\")\n",
    "            time.sleep(reset_time)\n",
    "    \n",
    "    return(final_list, no_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "conn = sqlite3.connect('tweets.db')\n",
    "c = conn.cursor()\n",
    "\n",
    "c.execute(\"\"\" SELECT twitter_user_id, politician_name, twitter_handle, election_year\n",
    "            FROM coordinates\n",
    "            WHERE twitter_active_during_election = 'True'\n",
    "            \"\"\")\n",
    "active_user_list = c.fetchall()\n",
    "print(active_user_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_list, no_tweets = format_tweets(active_user_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "conn = sqlite3.connect('tweets.db')\n",
    "c = conn.cursor()\n",
    "\n",
    "c.execute(\"\"\"CREATE TABLE tweets (\n",
    "          tweet_id INTEGER primary key,\n",
    "          user_id INTEGER,\n",
    "          user_name STRING,\n",
    "          user_handle STRING,\n",
    "          tweet_text STRING,\n",
    "          tweet_original_lang STRING,\n",
    "          tweet_translated STRING,\n",
    "          tweet_translated_lang STRING,\n",
    "          created_date DATETIME\n",
    "          )\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.execute('DROP TABLE tweets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload data in SQLite table\n",
    "# storing this data is important since this is an unofficial API\n",
    "# every time I access it, I am risking not being able to access it again\n",
    "\n",
    "c.executemany(\"INSERT INTO tweets VALUES (?,?,?,?,?,?,?)\", tweets2)\n",
    "conn.commit()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
