{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CODE TO CLEAN AND TRANSFORM WITH COUNTVECTORIZER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 48717)\t2\n",
      "  (0, 3111)\t1\n",
      "  (0, 35786)\t1\n",
      "  (0, 37702)\t2\n",
      "  (0, 16740)\t1\n",
      "  (0, 43869)\t1\n",
      "  (0, 23106)\t1\n",
      "  (0, 54138)\t1\n",
      "  (0, 54410)\t1\n",
      "  (0, 62179)\t1\n",
      "  (0, 50520)\t1\n",
      "  (0, 49835)\t1\n",
      "  (0, 57752)\t1\n",
      "  (0, 3228)\t1\n",
      "  (0, 21244)\t1\n",
      "  (0, 33988)\t1\n",
      "  (0, 51741)\t1\n",
      "  (0, 62409)\t2\n",
      "  (0, 35566)\t1\n",
      "  (0, 60670)\t1\n",
      "  (0, 5340)\t1\n",
      "  (0, 26790)\t1\n",
      "  (0, 11588)\t1\n",
      "  (0, 62385)\t1\n",
      "  (0, 48719)\t1\n",
      "  :\t:\n",
      "  (3235, 60915)\t1\n",
      "  (3235, 32244)\t1\n",
      "  (3235, 5576)\t1\n",
      "  (3235, 20136)\t1\n",
      "  (3235, 10941)\t1\n",
      "  (3235, 40042)\t1\n",
      "  (3235, 51439)\t1\n",
      "  (3235, 25724)\t1\n",
      "  (3235, 35762)\t1\n",
      "  (3235, 57613)\t1\n",
      "  (3235, 53003)\t1\n",
      "  (3235, 32246)\t1\n",
      "  (3235, 37907)\t1\n",
      "  (3235, 3392)\t1\n",
      "  (3235, 32040)\t1\n",
      "  (3235, 3611)\t1\n",
      "  (3235, 27075)\t1\n",
      "  (3235, 31593)\t1\n",
      "  (3235, 16406)\t1\n",
      "  (3235, 3582)\t1\n",
      "  (3235, 3408)\t1\n",
      "  (3235, 10944)\t1\n",
      "  (3235, 32682)\t1\n",
      "  (3235, 19760)\t1\n",
      "  (3235, 12261)\t1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#Open tweet data\n",
    "raw_data = pd.read_csv(r\"C:\\Users\\eaesp\\OneDrive\\Documents\\GitHub\\LIN-371\\Political Compass Project\\data\\Political Compass Coordinates Data - iteration 1 tweet data.csv\")\n",
    "\n",
    "#Pull the tweet text\n",
    "tweets_LST = raw_data['tweet translated']\n",
    "\n",
    "\n",
    "#Pull the coordinate points\n",
    "Xcoor_LST = raw_data['x coordinate']\n",
    "Ycoor_LST = raw_data['y coordinate']\n",
    "\n",
    "#X-Coordinate train test split\n",
    "Xtweets_train, Xtweets_test, xcoor_train, xcoor_test = train_test_split(tweets_LST, Xcoor_LST, test_size = 0.2, random_state = 1)\n",
    "#Y-Coordinate train test split\n",
    "Ytweets_train, Ytweets_test, ycoor_train, ycoor_test = train_test_split(tweets_LST, Ycoor_LST, test_size = 0.2, random_state = 3)\n",
    "\n",
    "#Vectorize X\n",
    "vectorizer = CountVectorizer(lowercase=True, ngram_range=(1,2))\n",
    "X_train = vectorizer.fit_transform(Xtweets_train.values.astype('U'))\n",
    "print(X_train)\n",
    "X_test = vectorizer.transform(Xtweets_test.values.astype('U'))\n",
    "#linR_modelX MAE is :  3.3098171359870276\n",
    "\n",
    "#Vectorize Y\n",
    "Y_train = vectorizer.fit_transform(Ytweets_train.values.astype('U'))\n",
    "Y_test = vectorizer.transform(Ytweets_test.values.astype('U'))\n",
    "#linR_modelY MAE is :  2.9701525145964913"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CODE TO CREATE X-AXIS LRM (COUNTVECTORIZER)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linR_modelX MAE is :  3.324459135445693\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "linR_modelX = LinearRegression()\n",
    "\n",
    "linR_modelX.fit(X_train, xcoor_train)\n",
    "y_hat_linR_X = linR_modelX.predict(X_test)\n",
    "\n",
    "accuracy_score_linR_X = metrics.mean_absolute_error(xcoor_test, y_hat_linR_X)\n",
    "\n",
    "print(\"linR_modelX MAE is : \", accuracy_score_linR_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CODE TO CREATE Y-AXIS LRM (COUNTVECTORIZER)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linR_modelY MAE is :  2.9710021466518857\n"
     ]
    }
   ],
   "source": [
    "linR_modelY = LinearRegression()\n",
    "\n",
    "linR_modelY.fit(Y_train, ycoor_train)\n",
    "y_hat_linR_Y = linR_modelY.predict(Y_test)\n",
    "\n",
    "accuracy_score_linR_Y = metrics.mean_absolute_error(ycoor_test, y_hat_linR_Y)\n",
    "\n",
    "print(\"linR_modelY MAE is : \", accuracy_score_linR_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CODE TO CLEAN AND TRANSFORM WITH GloVe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "words = dict()\n",
    "def add_dict(d, filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            line = line.split(' ')\n",
    "            try:\n",
    "                d[line[0]] = np.array(line[1:], dtype=float)\n",
    "            except:\n",
    "                continue\n",
    "add_dict(words, 'glove.6b/glove.6B.300d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def message_to_token(s):\n",
    "    tokens = tokenizer.tokenize(s)\n",
    "    lowercased_tokens = [t.lower() for t in tokens]\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(t) for t in lowercased_tokens]\n",
    "    useful_tokens = [t for t in lemmatized_tokens if t in words]\n",
    "    return useful_tokens\n",
    "    \n",
    "\n",
    "def message_to_vectors(message, dataframe, word_dict=words):\n",
    "    processed_list_of_tokens = message_to_token(message)\n",
    "    vectors = []\n",
    "    for token in processed_list_of_tokens:\n",
    "        if token not in word_dict:\n",
    "            continue\n",
    "        token_vector = word_dict[token]\n",
    "        vectors.append(token_vector)\n",
    "    new_row = pd.DataFrame({'vect_tweet' :[vectors]})\n",
    "    vecF = pd.concat([dataframe, new_row])\n",
    "    return vecF\n",
    "\n",
    "raw_data = pd.read_csv(\"Political Compass Coordinates Data - iteration 1 tweet data.csv\")\n",
    "tweets_LST = raw_data['tweet translated']\n",
    "vecDF = pd.DataFrame()\n",
    "\n",
    "for x in range(0,len(tweets_LST)):\n",
    "    curr_tweet = tweets_LST[x]\n",
    "    vecDF = message_to_vectors(curr_tweet,vecDF)\n",
    "\n",
    "\n",
    "#Pull the coordinate points\n",
    "Xcoor_LST = raw_data['x coordinate']\n",
    "Ycoor_LST = raw_data['y coordinate']\n",
    "\n",
    "tweetVectors = vecDF['vect_tweet']\n",
    "\n",
    "#X-Coordinate train test split\n",
    "Xtweets_train, Xtweets_test, xcoor_train, xcoor_test = train_test_split(tweetVectors, Xcoor_LST, test_size = 0.2, random_state = 1)\n",
    "#Y-Coordinate train test split\n",
    "Ytweets_train, Ytweets_test, ycoor_train, ycoor_test = train_test_split(tweetVectors, Ycoor_LST, test_size = 0.2, random_state = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CODE TO CREATE X-AXIS LRM (GloVe)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;31mTypeError\u001b[0m: float() argument must be a string or a real number, not 'list'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11456\\883180683.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mlinR_modelX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mlinR_modelX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtweets_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxcoor_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0my_hat_linR_X\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlinR_modelX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtweets_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0maccuracy_score_linR_X\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean_absolute_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxcoor_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_hat_linR_X\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\rylan\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1147\u001b[0m                 skip_parameter_validation=(\n\u001b[0;32m   1148\u001b[0m                     \u001b[0mprefer_skip_nested_validation\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mglobal_skip_validation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1149\u001b[0m                 )\n\u001b[0;32m   1150\u001b[0m             ):\n\u001b[1;32m-> 1151\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\rylan\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    674\u001b[0m         \u001b[0mn_jobs_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    676\u001b[0m         \u001b[0maccept_sparse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpositive\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"csr\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"csc\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"coo\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m         X, y = self._validate_data(\n\u001b[0m\u001b[0;32m    679\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_numeric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m         )\n\u001b[0;32m    681\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\rylan\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    617\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;34m\"estimator\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcheck_y_params\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    618\u001b[0m                     \u001b[0mcheck_y_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mdefault_check_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    619\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"y\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    620\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 621\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    622\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    623\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ensure_2d\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\rylan\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1143\u001b[0m         raise ValueError(\n\u001b[0;32m   1144\u001b[0m             \u001b[1;34mf\"{estimator_name} requires y to be passed, but the target y is None\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1145\u001b[0m         )\n\u001b[0;32m   1146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1147\u001b[1;33m     X = check_array(\n\u001b[0m\u001b[0;32m   1148\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1149\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1150\u001b[0m         \u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\rylan\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    914\u001b[0m                         )\n\u001b[0;32m    915\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 918\u001b[1;33m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    919\u001b[0m                 raise ValueError(\n\u001b[0;32m    920\u001b[0m                     \u001b[1;34m\"Complex data not supported\\n{}\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    921\u001b[0m                 ) from complex_warning\n",
      "\u001b[1;32mc:\\Users\\rylan\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[1;31m# Use NumPy API to support order\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    377\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    378\u001b[0m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    379\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 380\u001b[1;33m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    381\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m         \u001b[1;31m# At this point array is a NumPy ndarray. We convert it to an array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m         \u001b[1;31m# container that is consistent with the input's namespace.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\rylan\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   1996\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDTypeLike\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1997\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1998\u001b[1;33m         \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1999\u001b[0m         if (\n\u001b[0;32m   2000\u001b[0m             \u001b[0mastype_is_view\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2001\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0musing_copy_on_write\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "linR_modelX = LinearRegression()\n",
    "\n",
    "linR_modelX.fit(Xtweets_train, xcoor_train)\n",
    "y_hat_linR_X = linR_modelX.predict(Xtweets_test)\n",
    "\n",
    "accuracy_score_linR_X = metrics.mean_absolute_error(xcoor_test, y_hat_linR_X)\n",
    "\n",
    "print(\"linR_modelX MAE is : \", accuracy_score_linR_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CODE TO CREATE Y-AXIS LRM (GloVe)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "linR_modelX = LinearRegression()\n",
    "\n",
    "linR_modelX.fit(X_train, xcoor_train)\n",
    "y_hat_linR_X = linR_modelX.predict(X_test)\n",
    "\n",
    "accuracy_score_linR_X = metrics.mean_absolute_error(xcoor_test, y_hat_linR_X)\n",
    "\n",
    "print(\"linR_modelX MAE is : \", accuracy_score_linR_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CODE TO CREATE COORDINATE PLANE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tkinter as tk\n",
    "\n",
    "#tkinter interface code to ask for twitter handle\n",
    "#user_DAT = vectorizer.transform(None)\n",
    "#x = linR_modelX.predict(user_DAT)\n",
    "#y = linR_modelY.predict(user_DAT)\n",
    "x=1\n",
    "y=5\n",
    "fig, ax = plt.subplots(layout='constrained')\n",
    "ax.set_axisbelow(True)\n",
    "ax.spines['left'].set_position('center')\n",
    "ax.spines['bottom'].set_position('center')\n",
    "ax.spines['right'].set_color('none')\n",
    "ax.spines['top'].set_color('none')\n",
    "ax.grid(visible=True, linewidth=3, color='#a1a1a1')\n",
    "ax.set(xlim=(-10,10), xticks=np.arange(-10,11),\n",
    "       ylim=(-10,10), yticks=np.arange(-10,11))\n",
    "ax.fill_between([-10,0],-10,0,alpha=0.7, color='#98ed96') #GREEN\n",
    "ax.fill_between([0,10],-10,0,alpha=0.7, color='#bf9aed') #PURPLE\n",
    "ax.fill_between([-10,0],0,10,alpha=0.7, color='#fe7475') #RED\n",
    "ax.fill_between([0,10],0,10,alpha=0.7, color='#42aaff') #BLUE\n",
    "ax.scatter(x, y, s=300, color='#e3c51e',marker='*', linewidths=.5, edgecolors= '#000000')\n",
    "ax.annotate(('  '+str((x,y))), (x,y))\n",
    "ax.set_aspect('equal')\n",
    "plt.xticks(visible=False)\n",
    "plt.yticks(visible=False)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
