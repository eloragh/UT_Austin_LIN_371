{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from twikit import Client\n",
    "from twikit import TwitterException \n",
    "from twikit import TooManyRequests\n",
    "from twikit.utils import Endpoint\n",
    "from twikit import BadRequest\n",
    "from requests import ReadTimeout\n",
    "from twikit import Unauthorized\n",
    "from translate import Translator\n",
    "from math import ceil\n",
    "import time\n",
    "import json\n",
    "import requests\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this API requires authentication\n",
    "f = open('authentication.txt', 'r')\n",
    "auth = f.read()\n",
    "f.close()\n",
    "auth_token = auth.split(\"\\n\")\n",
    "\n",
    "# don't hardcode your email and password into something!!!\n",
    "# the auth is in gitignore so I won't get hacked\n",
    "username = str(auth_token[0])\n",
    "email = str(auth_token[1])\n",
    "password = str(auth_token[2])\n",
    "\n",
    "# Initialize client\n",
    "client = Client(language='en-US', http2=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def authentication(username, email, password):\n",
    "    try:\n",
    "        # Login to the service with provided user credentials\n",
    "        client.login(\n",
    "            auth_info_1=username ,\n",
    "            auth_info_2=email,\n",
    "            password=password)\n",
    "\n",
    "        print(\"Login successful!\")\n",
    "        return True\n",
    "\n",
    "    except BadRequest:\n",
    "        print(\"Login unsuccessful. One or more login parameters is incorrect.\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login successful!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authentication(username, email, password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Twitter LOVES to ban people when they log in repeatedly\n",
    "# saving the cookies makes sure I don't get banned (often)\n",
    "\n",
    "client.get_cookies()\n",
    "client.save_cookies('IGNOREcookies.json')\n",
    "with open('IGNOREcookies.json', 'r', encoding='UTF8') as f:\n",
    "    client.set_cookies(json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# housekeeping function\n",
    "# each different method uses a different API endpoint\n",
    "# each different API endpoint has a rate limit\n",
    "# you can hit it a certain number of times per a time period (usually 15 minutes)\n",
    "# this tells me how much time I have left if I've hit the rate limit\n",
    "\n",
    "def get_limit_reset_time(endpoint: str):\n",
    "    res = requests.get(\n",
    "        endpoint,\n",
    "        headers=client._base_headers,\n",
    "        cookies=client.get_cookies()\n",
    "    )\n",
    "    return ceil(int(res.headers['x-rate-limit-reset']) - time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rate_limit_search_tweet():\n",
    "    try:\n",
    "        print(client.search_tweet(\n",
    "            f'from:JoeBiden since:2020-01-01 until:2021-03-01', 'Latest', count=40\n",
    "        ))\n",
    "    except TooManyRequests:\n",
    "        reset_time = get_limit_reset_time(Endpoint.USER_TWEETS)\n",
    "        print(f'rate limit is reset after {reset_time} seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rate_limit_tweet_by_id():\n",
    "    try:\n",
    "        print(client.get_tweet_by_id(1351951465674276869))\n",
    "    except TooManyRequests:\n",
    "        reset_time = get_limit_reset_time(Endpoint.USER_TWEETS)\n",
    "        print(f'rate limit is reset after {reset_time} seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# another housekeeping function\n",
    "# if I'm suddenly getting 403 errors, I can use this to check if I've been banned\n",
    "# sometimes I just have to go on the browser and reauthenticate\n",
    "\n",
    "def check_user_status(user_id):\n",
    "    \"\"\"\n",
    "    True if the user is active, otherwise false (not exists or suspended).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        client.get_user_by_id(user_id)\n",
    "    except TwitterException as e:\n",
    "        if str(e).startswith('Invalid user id'):\n",
    "            return False\n",
    "        raise e\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "check_user_status(1547081484695216130)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT: the user handle, a beginning and end of a date range\n",
    "# OUTPUT: the user handle, the user_ID, and the scraped tweets\n",
    "def get_all_tweets(handle, since, until):\n",
    "\n",
    "    try:\n",
    "        # load the cookies so you don't login a million times and get banned\n",
    "        client.load_cookies('IGNOREcookies.json')\n",
    "\n",
    "        # initialize the list we will store our data in\n",
    "        mass_tweets = []\n",
    "\n",
    "        since = f'{since}-01-01'\n",
    "        until = f'{until}-01-31'\n",
    "\n",
    "        # this will pull the first forty tweets\n",
    "        tweets = client.search_tweet(\n",
    "            f'from:{handle} since:{since} until:{until}', 'Top'\n",
    "        )\n",
    "        tweets1 = [tweet.id for tweet in tweets]\n",
    "        mass_tweets += tweets1\n",
    "\n",
    "        # this endpoint has a rate limit of 50 hits per 15 minutes\n",
    "        # 15 min = 900 seconds\n",
    "        # 900//50 = 18\n",
    "        # allows the program to be automated\n",
    "        time.sleep(18)\n",
    "        \n",
    "        # if it returns an empty list, the user had no available tweets during the date time range\n",
    "        if len(tweets) == 0:\n",
    "            return([])\n",
    "        \n",
    "        # this will keep looking for tweets until a certain number of them has been reached\n",
    "        while len(tweets) > 0 and len(mass_tweets) < 30:\n",
    "\n",
    "            # this API provides a 'tweet' object, but we only want the id when we return\n",
    "            tweets = tweets.next()\n",
    "            tweets1 = [tweet.id for tweet in tweets]\n",
    "            mass_tweets += tweets1\n",
    "            time.sleep(18) # cooldown\n",
    "\n",
    "            # keep pulling tweets until number is hit or there are none left\n",
    "\n",
    "            # we need to make a check in case we've hit the max number of tweets we can scrape\n",
    "            # this prevents us from pinging the API for no reason\n",
    "            if len(tweets) == 0:\n",
    "                break\n",
    "            else:\n",
    "                continue\n",
    "        \n",
    "    except ReadTimeout:\n",
    "        return(mass_tweets)\n",
    "\n",
    "    return(mass_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tweets(handle, user_id, name, tweet_ids, since):\n",
    "    # load the cookies so you don't login a million times and get banned\n",
    "    client.load_cookies('IGNOREcookies.json')\n",
    "\n",
    "    # initialize a list to store all tuples\n",
    "    tweets = []\n",
    "\n",
    "    for tweet_id in tweet_ids:\n",
    "        try:\n",
    "            # using the IDs we pulled from above\n",
    "            tweet = client.get_tweet_by_id(tweet_id)\n",
    "\n",
    "            # we have international data\n",
    "            # this will translate it and identify it's translation\n",
    "            if tweet.lang != 'en':\n",
    "                translator = Translator(to_lang='en')\n",
    "                tweet_text = translator.translate(tweet.text)\n",
    "                tweets.append([int(tweet.id), int(user_id), name, handle, str(tweet_text), str(tweet.lang), 'True', 'en', str(tweet.created_at_datetime), since])\n",
    "\n",
    "            # otherwise we just move on\n",
    "            else:\n",
    "                tweets.append((int(tweet.id), int(user_id), name, handle, str(tweet.text), str(tweet.lang), 'False', 'null', str(tweet.created_at_datetime), since))\n",
    "\n",
    "            # this endpoint can process 150 tweets per 15 minutes\n",
    "            # 15 min = 900 seconds\n",
    "            # 900//150 = 6\n",
    "            # allows program to be fully automated\n",
    "            time.sleep(6)\n",
    "\n",
    "        # it throws an Index Error if the tweet has been deleted/ is not available\n",
    "        except IndexError:\n",
    "            print(f'Index Error: unable to process {tweet} from {name}')\n",
    "        except ReadTimeout:\n",
    "            print('Read timeout')\n",
    "            return tweets\n",
    "    return tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pull_tweet_ids(user_list):\n",
    "    tweet_ids_list = []\n",
    "    no_tweets_list = []\n",
    "\n",
    "    for idx, user in enumerate(user_list):\n",
    "\n",
    "        try:\n",
    "            # all of our parameters for the function\n",
    "            user_id = user[0]\n",
    "            name = user[1]\n",
    "            handle = user[2]\n",
    "            since = user[3]\n",
    "            until = user[3] + 1\n",
    "\n",
    "            print(name)\n",
    "\n",
    "            # pull tweet IDs that we will user in second while loop\n",
    "            tweet_ids = get_all_tweets(handle, since=since, until=until)\n",
    "            print(f'{len(tweet_ids)} tweets collected for {name} for {since} election')\n",
    "\n",
    "            # we only add to the counter if that person actually had tweets to process\n",
    "            if len(tweet_ids) > 0:\n",
    "                tweet_ids_list.append([handle, user_id, name, tweet_ids, since])\n",
    "            \n",
    "            # I want to keep track of which politicians didn't tweet during their election year\n",
    "            else:\n",
    "                no_tweets_list.append([user_id, name, handle, since])\n",
    "\n",
    "        # this error happens when we try to hit the API too many times\n",
    "        except TooManyRequests:\n",
    "            print(\"Too many requests\")\n",
    "            print(get_rate_limit_search_tweet())\n",
    "            time.sleep(900)\n",
    "        \n",
    "        # I honestly don't know why this error happens\n",
    "        # I'm too speedy for the requests module I guess\n",
    "        except ReadTimeout:\n",
    "            print(\"\"\"\"The read operation timed out.\n",
    "                      If authentication fails, you may be blocked or need to authenticate through a browser.\"\"\")\n",
    "            if authentication(username, email, password):\n",
    "                continue\n",
    "            elif not check_user_status(1547081484695216130):\n",
    "                print(\"Authentication failed. Function pull_tweet_ids terminating.\")\n",
    "                return idx, (tweet_ids_list, no_tweets_list)\n",
    "            else:\n",
    "                print(\"Unknown authentication issue. Function pull_tweet_ids terminating.\")\n",
    "                return idx, (tweet_ids_list, no_tweets_list)\n",
    "        \n",
    "        # elon musk caught my scent :(\n",
    "        # reauthenticate in a browser\n",
    "        except Unauthorized:\n",
    "            if authentication(username, email, password):\n",
    "                continue\n",
    "            else:\n",
    "                print(\"You need to reauthenticate through a browser.\")\n",
    "                return idx, (tweet_ids_list, no_tweets_list)\n",
    "\n",
    "    print(f'This program was able to find tweets for {len(tweet_ids_list)} out of {len(user_list)} politicians.')\n",
    "    print(f'{len(no_tweets_list)} politicians had no tweets during one or more of their campaign years.')\n",
    "    return tweet_ids_list, no_tweets_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pulled_tweet_ids(tweet_ids_list, num_tweets):\n",
    "\n",
    "    tweet_list = []\n",
    "\n",
    "    for user in tweet_ids_list:\n",
    "        try:\n",
    "\n",
    "            # all the parameters we need\n",
    "            handle = user[0]\n",
    "            user_id = user[1]\n",
    "            name = user[2]\n",
    "            tweet_ids = user[3]\n",
    "            year = user[4]\n",
    "            \n",
    "            # we only want to do up to 25 tweets per politician\n",
    "            # this means we can process 6 politicians per rate timeout\n",
    "            # 150 tweets per 15 minutes\n",
    "            # not great but it's free\n",
    "\n",
    "            if len(tweet_ids) > num_tweets:\n",
    "                # random sample in an attempt to stay unbiased\n",
    "                tweet_ids = random.sample(tweet_ids, num_tweets)\n",
    "            \n",
    "            # process the tweets and add them to our holding list from above\n",
    "            tweets = process_tweets(handle, user_id, name, tweet_ids, year)\n",
    "            tweet_list.append(tweets)\n",
    "            print(f\"{num_tweets} tweets processed for {name}\")\n",
    "        \n",
    "        except TooManyRequests:\n",
    "            print(\"Too many requests\")\n",
    "            print(get_rate_limit_tweet_by_id())\n",
    "            time.sleep(900)\n",
    "\n",
    "        except ReadTimeout:\n",
    "            print(\"\"\"\"The read operation timed out.\n",
    "                      If authentication fails, you may be blocked or need to authenticate through a browser.\"\"\")\n",
    "            if authentication(username, email, password):\n",
    "                continue\n",
    "            elif not check_user_status(1547081484695216130):\n",
    "                print(\"Authentication failed. Function pull_tweet_ids terminating.\")\n",
    "                return tweet_list\n",
    "            else:\n",
    "                print(\"Unknown authentication issue. Function pull_tweet_ids terminating.\")\n",
    "                return tweet_list\n",
    "\n",
    "    return tweet_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(813286, 'Barack Obama', 'BarackObama', 2008)\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "conn = sqlite3.connect('tweets.db')\n",
    "c = conn.cursor()\n",
    "\n",
    "c.execute(\"\"\" SELECT twitter_user_id, politician_name, twitter_handle, election_year\n",
    "            FROM coordinates\n",
    "            WHERE twitter_active_during_election = 'True'\n",
    "            \"\"\")\n",
    "active_user_list = c.fetchall()\n",
    "print(active_user_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193\n"
     ]
    }
   ],
   "source": [
    "user_list = active_user_list.copy()\n",
    "print(len(user_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Barack Obama\n",
      "39 tweets collected for Barack Obama for 2008 election\n",
      "Joe Biden\n",
      "0 tweets collected for Joe Biden for 2008 election\n",
      "Dennis Kucinich\n",
      "38 tweets collected for Dennis Kucinich for 2008 election\n",
      "Mike Huckabee\n",
      "39 tweets collected for Mike Huckabee for 2008 election\n",
      "Fred Thompson\n",
      "0 tweets collected for Fred Thompson for 2008 election\n",
      "Chris Dodd\n",
      "39 tweets collected for Chris Dodd for 2008 election\n",
      "Jill Stein\n",
      "23 tweets collected for Jill Stein for 2012 election\n",
      "Barack Obama\n",
      "39 tweets collected for Barack Obama for 2012 election\n",
      "Mitt Romney\n",
      "29 tweets collected for Mitt Romney for 2012 election\n",
      "Virgil Goode\n",
      "11 tweets collected for Virgil Goode for 2012 election\n",
      "Gary Johnson\n",
      "0 tweets collected for Gary Johnson for 2012 election\n",
      "Newt Gingrich\n",
      "39 tweets collected for Newt Gingrich for 2012 election\n",
      "Ron Paul\n"
     ]
    }
   ],
   "source": [
    "tweet_ids, no_tweets = pull_tweet_ids(user_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(tweet_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_list = process_pulled_tweet_ids(tweet_ids, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x22f25006e40>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sqlite3\n",
    "conn = sqlite3.connect('tweets.db')\n",
    "c = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload data in SQLite table\n",
    "# storing this data is important since this is an unofficial API\n",
    "# every time I access it, I am risking not being able to access it again\n",
    "\n",
    "for lst in tweet_list:\n",
    "    for tweet in lst:\n",
    "        c.execute(\"INSERT INTO politician_tweets VALUES (?,?,?,?,?,?,?,?,?,?)\", tweet)\n",
    "        conn.commit()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
